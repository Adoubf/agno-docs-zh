---
title: Langfuse
description: 将Agno与Langfuse集成，发送追踪数据并获取智能体性能的深入洞察。
---
## 将 Agno 与 Langfuse 集成

Langfuse 提供了一个强大的平台用于追踪和监控 AI 模型调用。通过将 Agno 与 Langfuse 集成，您可以使用 OpenInference 和 OpenLIT 发送追踪数据，从而深入了解智能体的性能表现。

## 前提条件

1. **安装依赖项**

   确保已安装必要的软件包：

   ```bash
   pip install agno openai langfuse opentelemetry-sdk opentelemetry-exporter-otlp openinference-instrumentation-agno
   ```

2. **设置 Langfuse 账户**

   - 选择自托管或在 [Langfuse](https://us.cloud.langfuse.com) 注册账户。
   - 从 Langfuse 仪表板获取您的公钥和私密 API 密钥。

3. **配置环境变量**

   使用 Langfuse API 密钥配置您的环境：

   ```bash
   export LANGFUSE_PUBLIC_KEY=<your-public-key>
   export LANGFUSE_SECRET_KEY=<your-secret-key>
   ```

## 向 Langfuse 发送追踪数据

- ### 示例：使用 Langfuse 与 OpenInference

本示例演示如何通过 OpenInference 对 Agno 智能体进行插装，并向 Langfuse 发送追踪数据。

```python
import base64
import os

from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.yfinance import YFinanceTools
from openinference.instrumentation.agno import AgnoInstrumentor
from opentelemetry import trace as trace_api
from opentelemetry.exporter.otlp.proto.http.trace_exporter import OTLPSpanExporter
from opentelemetry.sdk.trace import TracerProvider
from opentelemetry.sdk.trace.export import SimpleSpanProcessor

# 为 Langfuse 设置环境变量
LANGFUSE_AUTH = base64.b64encode(
    f"{os.getenv('LANGFUSE_PUBLIC_KEY')}:{os.getenv('LANGFUSE_SECRET_KEY')}".encode()
).decode()
os.environ["OTEL_EXPORTER_OTLP_ENDPOINT"] = "https://us.cloud.langfuse.com/api/public/otel"
os.environ["OTEL_EXPORTER_OTLP_HEADERS"] = f"Authorization=Basic {LANGFUSE_AUTH}"

# 配置追踪器提供程序
tracer_provider = TracerProvider()
tracer_provider.add_span_processor(SimpleSpanProcessor(OTLPSpanExporter()))
trace_api.set_tracer_provider(tracer_provider=tracer_provider)

# 开始检测 agno
AgnoInstrumentor().instrument()

# 创建并配置智能体
agent = Agent(
    name="Stock Price Agent",
    model=OpenAIChat(id="gpt-4o-mini"),
    tools=[YFinanceTools()],
    instructions="You are a stock price agent. Answer questions in the style of a stock analyst.",
    debug_mode=True,
)

# 使用智能体
agent.print_response("What is the current price of Tesla?")
```

- ### 示例：使用 Langfuse 与 OpenLIT

本示例演示如何通过 OpenLIT 使用 Langfuse 追踪模型调用。

```python
import base64
import os

from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.duckduckgo import DuckDuckGoTools
from opentelemetry.exporter.otlp.proto.http.trace_exporter import OTLPSpanExporter
from opentelemetry.sdk.trace import TracerProvider
from opentelemetry.sdk.trace.export import SimpleSpanProcessor
from opentelemetry import trace

# 为 Langfuse 设置环境变量
LANGFUSE_AUTH = base64.b64encode(
    f"{os.getenv('LANGFUSE_PUBLIC_KEY')}:{os.getenv('LANGFUSE_SECRET_KEY')}".encode()
).decode()
os.environ["OTEL_EXPORTER_OTLP_ENDPOINT"] = "https://us.cloud.langfuse.com/api/public/otel"
os.environ["OTEL_EXPORTER_OTLP_HEADERS"] = f"Authorization=Basic {LANGFUSE_AUTH}"

# 配置追踪器提供程序
trace_provider = TracerProvider()
trace_provider.add_span_processor(SimpleSpanProcessor(OTLPSpanExporter()))
trace.set_tracer_provider(trace_provider)

# 初始化 OpenLIT 检测
import openlit
openlit.init(tracer=trace.get_tracer(__name__), disable_batch=True)

# 创建并配置智能体
agent = Agent(
    model=OpenAIChat(id="gpt-4o-mini"),
    tools=[DuckDuckGoTools()],
    markdown=True,
    debug_mode=True,
)

# 使用智能体
agent.print_response("What is currently trending on Twitter?")
```

## 注意事项

- **环境变量**：请确保正确设置了 API 密钥和 OTLP 端点的环境变量。
- **数据区域**：根据需要调整 `OTEL_EXPORTER_OTLP_ENDPOINT` 以匹配您的数据区域或本地部署。可用区域包括：
  - `https://us.cloud.langfuse.com/api/public/otel` 美国区域
  - `https://eu.cloud.langfuse.com/api/public/otel` 欧盟区域
  - `http://localhost:3000/api/public/otel` 本地部署

遵循上述步骤，您可以高效地将 Agno 与 Langfuse 集成，从而实现对 AI 智能体的全面可观测性和监控。