---
title: Basics
---

With phidata, we build AI applications using **Assistants**.

**Assistants** use LLMs to achieve tasks by [calling functions](https://platform.openai.com/docs/guides/function-calling). They come with built-in memory, knowledge and storage, making it easy to build autonomous AI applications.

![Assistant](/images/assistant.png)

## Basic Assistant

<Steps>
  <Step title="Create a virtual environment">
    Open the `Terminal` and create an `ai` directory with a python virtual environment.

    <CodeGroup>

    ```bash Mac
    mkdir ai && cd ai

    python3 -m venv aienv
    source aienv/bin/activate
    ```

    ```bash Windows
    mkdir ai; cd ai

    python3 -m venv aienv
    aienv/scripts/activate
    ```

    </CodeGroup>

  </Step>
  <Step title="Install libraries">
    Install `phidata` and `openai`

    <CodeGroup>

    ```bash Mac
    pip install -U phidata openai
    ```

    ```bash Windows
    pip install -U phidata openai
    ```

    </CodeGroup>

  </Step>
  <Step title="Create an assistant">
    Create a file `assistant.py` with the following contents

    ```python assistant.py
    from phi.assistant import Assistant

    assistant = Assistant(description="You help people with their health and fitness goals.")
    assistant.print_response("Share a quick healthy breakfast recipe.")
    ```

  </Step>
  <Step title="Set your OpenAI key">

    Set the `OPENAI_API_KEY` environment variable to your OpenAI Key. You can get one [from OpenAI here](https://platform.openai.com/account/api-keys). Otherwise `phi` provides ready to use access to OpenAI models.

    <CodeGroup>

    ```bash Mac
    export OPENAI_API_KEY=sk-***
    ```

    ```bash Windows
    setx OPENAI_API_KEY sk-***
    ```

    </CodeGroup>

  </Step>
  <Step title="Run the assistant">
    Run the `assistant.py` file

    ```bash
    python assistant.py
    ```

  </Step>
</Steps>

## Assistant with tools

**Tools** are functions that the Assistant can run to achieve tasks.

### Web Search

Lets create an Assistant that can search the web using DuckDuckGo

<Steps>
  <Step title="Create DuckDuckGo Assistant">
    Create a file `ddg_assistant.py`

    ```python ddg_assistant.py
    from phi.assistant import Assistant
    from phi.tools.duckduckgo import DuckDuckGo

    assistant = Assistant(tools=[DuckDuckGo()], show_tool_calls=True)
    assistant.print_response("Whats happening in France? Summarize top stories with sources.")
    ```

  </Step>
  <Step title="Run the assistant">
    Install duckduckgo search

    ```shell
    pip install duckduckgo-search
    ```

    Run the `ddg_assistant.py`

    ```bash
    python ddg_assistant.py
    ```

  </Step>
</Steps>

### Data Analysis

Lets create a Data Assistant that uses DuckDb to analyze data using SQL.

<Steps>
  <Step title="Create a DuckDbAssistant">
    Create a file `data_assistant.py`

    ```python data_assistant.py
    import json
    from phi.assistant.duckdb import DuckDbAssistant

    duckdb_assistant = DuckDbAssistant(
        semantic_model=json.dumps({
            "tables": [
                {
                    "name": "movies",
                    "description": "Contains information about movies from IMDB.",
                    "path": "https://phidata-public.s3.amazonaws.com/demo_data/IMDB-Movie-Data.csv",
                }
            ]
        }),
    )

    duckdb_assistant.print_response("What is the average rating of movies? Show me the SQL.")
    ```

  </Step>
  <Step title="Run the assistant">
    Install duckdb

    ```shell
    pip install duckdb
    ```

    Run the `data_assistant.py`

    ```bash
    python data_assistant.py
    ```

  </Step>
</Steps>

### Python Assistant

The `PythonAssistant` can perform virtually any task using python code.

<Steps>
  <Step title="Create a PythonAssistant">
    Create a file `python_assistant.py`

    ```python python_assistant.py
    from phi.assistant.python import PythonAssistant
    from phi.file.local.csv import CsvFile

    python_assistant = PythonAssistant(
        files=[
            CsvFile(
                path="https://phidata-public.s3.amazonaws.com/demo_data/IMDB-Movie-Data.csv",
                description="Contains information about movies from IMDB.",
            )
        ],
        pip_install=True,
        show_tool_calls=True,
    )

    python_assistant.print_response("What is the average rating of movies?")
    ```

  </Step>
  <Step title="Run the assistant">
    Install pandas using

    ```
    pip install pandas
    ```

    Run the `python_assistant.py`

    ```bash
    python python_assistant.py
    ```

  </Step>
</Steps>

## Knowledge Base

Knowledge Base is a database of information that the Assistant can search to improve its responses. This information provides extra context to language models so they respond in a context-aware manner.

While any type of storage can act as a knowledge base, vector databases offer the best solution for retrieving relevant results from dense information quickly. Let's use `PgVector` as our vector store as it can also provide long-term storage for our Assistants.

### Run PgVector

Run `PgVector` on `Docker` using the following steps:

<Steps>
  <Step title="Install Docker">
    Install [docker desktop](https://docs.docker.com/desktop/install/mac-install/) for running PgVector in a container.
  </Step>
  <Step title="Define PgVector as a resource">
    Create a file `resources.py` with the following contents

    ```python resources.py
    from phi.docker.app.postgres import PgVectorDb
    from phi.docker.resources import DockerResources

    # -*- PgVector2 running on port 5432:5432
    vector_db = PgVectorDb(
        pg_user="ai",
        pg_password="ai",
        pg_database="ai",
        debug_mode=True,
    )

    # -*- DockerResources
    dev_docker_resources = DockerResources(apps=[vector_db])
    ```

  </Step>
  <Step title="Start PgVector">
    Start `resources.py` using:

    ```bash
    phi start resources.py
    ```

    **Press Enter** to confirm. You can verify container status on the docker dashboard.

  </Step>
</Steps>

## RAG Assistant

Retrieval Augmented Generation means providing the LLM with additional information so it responds in a context-aware manner. When a user sends a message, we **"stuff the prompt with relevant information"** to improve response quality.

Let's test out RAG by building a **PDF Assistant** that helps us with food recipes.

1. We'll load the knowledge base with the PDF of a recipe book.
2. Our **PDF Assistant** will respond with the recipes from the knowledge base.

<Tip>
  A recipe book is a great way to test RAG because it contains images, random
  fonts and requires the assistant to synthesize the data from the knowledge
  base.
</Tip>

<Steps>
  <Step title="Install libraries">
    Install the required libraries using pip

    <CodeGroup>

    ```bash Mac
    pip install -U pgvector pypdf psycopg sqlalchemy
    ```

    ```bash Windows
    pip install -U pgvector pypdf psycopg sqlalchemy
    ```

    </CodeGroup>

  </Step>
  <Step title="Create a RAG Assistant">
    Create a file `rag_assistant.py` with the following contents

    ```python rag_assistant.py
    from phi.assistant import Assistant
    from phi.knowledge.pdf import PDFUrlKnowledgeBase
    from phi.vectordb.pgvector import PgVector2

    from resources import vector_db

    # The PDFUrlKnowledgeBase reads PDFs from urls and loads
    # the `ai.recipes` table when`knowledge_base.load()` is called.
    knowledge_base = PDFUrlKnowledgeBase(
        urls=["https://phi-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf"],
        vector_db=PgVector2(collection="recipes", db_url=vector_db.get_db_connection_local()),
    )
    knowledge_base.load(recreate=False)

    assistant = Assistant(
        knowledge_base=knowledge_base,
        # The add_references_to_prompt flag searches the knowledge base
        # and updates the prompt sent to the LLM.
        add_references_to_prompt=True,
    )

    assistant.print_response("How do I make pad thai?")
    ```

  </Step>
  <Step title="Run the assistant">
    Run the `rag_assistant.py` file. Give it a few minutes to load the knowledge base and see it respond with recipes from the recipe book.

    <CodeGroup>

    ```bash Mac
    python rag_assistant.py
    ```

    ```bash Windows
    python rag_assistant.py
    ```

    </CodeGroup>

  </Step>
</Steps>

<Accordion title="Use local PDFs">
If you want to use local PDFs, use a `PDFKnowledgeBase` instead

```python assistant.py
from phi.knowledge.pdf import PDFKnowledgeBase

...
knowledge_base = PDFKnowledgeBase(
    path="data/pdfs",
    vector_db=PgVector2(
        collection="pdf_documents",
        db_url=vector_db.get_db_connection_local(),
    ),
)
...
```

</Accordion>

## Autonomous Assistant

With the RAG assistant above, the `add_references_to_prompt=True` always adds information from the knowledge base to the prompt, regardless of whether it is helpful.

With Autonomous assistants, we let the LLM decide **if** it needs to access the knowledge base and what search parameters it needs to query the knowledge base.

Make the `Assistant` Autonomous by setting `use_tools=True` - which gives it the ability to search the knowledge base and chat history on demand.

<Steps>
  <Step title="Create an Autonomous Assistant">
    Create a file `auto_assistant.py` with the following contents

    ```python auto_assistant.py
    from phi.assistant import Assistant
    from phi.knowledge.pdf import PDFUrlKnowledgeBase
    from phi.vectordb.pgvector import PgVector2

    from resources import vector_db

    knowledge_base = PDFUrlKnowledgeBase(
        urls=["https://phi-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf"],
        vector_db=PgVector2(collection="recipes", db_url=vector_db.get_db_connection_local()),
    )
    # Comment out as the knowledge base is already loaded.
    # knowledge_base.load(recreate=False)

    assistant = Assistant(
        knowledge_base=knowledge_base,
        # add_references_to_prompt=True,
        use_tools=True,
        show_tool_calls=True,
    )

    assistant.print_response("How do I make pad thai?")
    assistant.print_response("What was my last question?")
    ```

  </Step>
  <Step title="Run the assistant">
    Run the `auto_assistant.py` and notice how it searches the knowledge base and chat history when needed.

    <CodeGroup>

    ```bash Mac
    python auto_assistant.py
    ```

    ```bash Windows
    python auto_assistant.py
    ```

    </CodeGroup>

  </Step>
</Steps>

## Storage & Memory

Every `Assistant` comes with built-in memory but it only lasts while the session is active. To provide long-term memory we use a `Storage` backend like `PostgreSQL`.

<Steps>
  <Step title="Create a PDF Assistant with Knowledge and Storage">

    Create a file `pdf_assistant.py` with the following contents

```python pdf_assistant.py
import typer
from rich.prompt import Prompt
from typing import Optional, List
from phi.assistant import Assistant
from phi.storage.assistant.postgres import PgAssistantStorage
from phi.knowledge.pdf import PDFUrlKnowledgeBase
from phi.vectordb.pgvector import PgVector2

from resources import vector_db

knowledge_base = PDFUrlKnowledgeBase(
    urls=["https://phi-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf"],
    vector_db=PgVector2(
        collection="recipes",
        db_url=vector_db.get_db_connection_local(),
    ),
)
# Comment out after first run
knowledge_base.load(recreate=False)

storage = PgAssistantStorage(
    table_name="pdf_assistant",
    db_url=vector_db.get_db_connection_local(),
)


def pdf_assistant(new: bool = False, user: str = "user"):
    run_id: Optional[str] = None

    if not new:
        existing_run_ids: List[str] = storage.get_all_run_ids(user)
        if len(existing_run_ids) > 0:
            run_id = existing_run_ids[0]

    assistant = Assistant(
        run_id=run_id,
        user_id=user,
        knowledge_base=knowledge_base,
        storage=storage,
        # use_tools=True adds functions to
        # search the knowledge base and chat history
        use_tools=True,
        show_tool_calls=True,
        # Uncomment the following line to use traditional RAG
        # add_references_to_prompt=True,
    )
    if run_id is None:
        run_id = assistant.run_id
        print(f"Started Run: {run_id}\n")
    else:
        print(f"Continuing Run: {run_id}\n")

    while True:
        message = Prompt.ask(f"[bold] :sunglasses: {user} [/bold]")
        if message in ("exit", "bye"):
            break
        assistant.print_response(message)


if __name__ == "__main__":
    typer.run(pdf_assistant)
```

  </Step>
  <Step title="Run the PDF Assistant">
    Run the `pdf_assistant.py` file.

    <CodeGroup>

    ```bash Mac
    python pdf_assistant.py
    ```

    ```bash Windows
    python pdf_assistant.py
    ```

    </CodeGroup>

  </Step>
  <Step title="Ask Questions">

    Now the assistant continues across sessions. Ask a question:

    ```
    How do I make pad that?
    ```

    Then message `bye` to exit, start the app again and ask:

    ```
    What was my last message?
    ```

    Run the `pdf_assistant.py` file with the `--new` flag to start a new run.

    <CodeGroup>

    ```bash Mac
    python pdf_assistant.py --new
    ```

    ```bash Windows
    python pdf_assistant.py --new
    ```

    </CodeGroup>

  </Step>
</Steps>

## Stop PgVector

Play around and then stop `PgVector` using `phi stop resources.py`

<CodeGroup>

```bash Mac
phi stop resources.py
```

```bash Windows
phi stop resources.py
```

</CodeGroup>

## Next

Congratulations on building an AI Assistant that can operate in RAG or Autonomous mode, with access to a knowledge base and storage. We can serve this Assistant in production using an Api built with `FastApi`, front-end built with `Streamlit` or a Web App built with `Django`

Instead of wiring tools manually, phidata provides **pre-built templates** that you can run locally or on AWS with just 1 command. These templates are fully customizable and used by many teams in production. Checkout one of the examples below to start building

<Snippet file="examples.mdx" />
