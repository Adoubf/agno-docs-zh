---
title: 流式智能体
---
## 代码

```python cookbook/models/ollama/basic_stream.py
from typing import Iterator  # noqa
from agno.agent import Agent, RunResponse  # noqa
from agno.models.ollama import Ollama

agent = Agent(model=Ollama(id="llama3.1:8b"), markdown=True)

# 将响应存储在变量中
# 运行响应: Iterator[RunResponse] = 智能体.run("分享一个2句的恐怖故事", stream=True)
# for chunk in run_response:
# print(chunk.content)

# 在终端打印响应
agent.print_response("Share a 2 sentence horror story", stream=True)
```

## 使用说明

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="安装 Ollama">
    按照[安装指南](https://github.com/ollama/ollama?tab=readme-ov-file#macos)操作并运行:
    ```bash
    ollama pull llama3.1:8b
    ```
  </Step>

  <Step title="安装库">
    ```bash
    pip install -U ollama agno
    ```
  </Step>

  <Step title="运行智能体">
    <CodeGroup>
    ```bash Mac
    python cookbook/models/ollama/basic_stream.py
    ```

    ```bash Windows
    python cookbook/models/ollama/basic_stream.py
    ```
    </CodeGroup>
  </Step>
</Steps>