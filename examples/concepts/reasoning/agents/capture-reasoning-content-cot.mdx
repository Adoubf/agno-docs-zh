---
title: 捕捉推理内容
---
本示例演示如何在使用 `reasoning=True` 或设置特定 `reasoning_model` 时访问并打印 `reasoning_content`。

## 代码

```python cookbook/reasoning/agents/capture_reasoning_content_default_COT.py

from agno.agent import Agent
from agno.models.openai import OpenAIChat

print("\n=== Example 1: Using reasoning=True (default COT) ===\n")

# 创建智能体并启用推理功能（默认模型为COT）
agent = Agent(
    model=OpenAIChat(id="gpt-4o"),
    reasoning=True,
    markdown=True,
)

# 运行智能体（非流式）
print("Running with reasoning=True (non-streaming)...")
response = agent.run("What is the sum of the first 10 natural numbers?")

# 打印推理内容
print("\n--- reasoning_content from response ---")
if hasattr(response, "reasoning_content") and response.reasoning_content:
    print(response.reasoning_content)
else:
    print("No reasoning_content found in response")


print("\n\n=== Example 2: Using a custom reasoning_model ===\n")

# 创建具有特定推理模型的智能体
agent_with_reasoning_model = Agent(
    model=OpenAIChat(id="gpt-4o"),
    reasoning_model=OpenAIChat(id="gpt-4o"),  # Should default to manual COT
    markdown=True,
)

# 运行智能体（非流式模式）
print("Running with reasoning_model specified (non-streaming)...")
response = agent_with_reasoning_model.run(
    "What is the sum of the first 10 natural numbers?"
)

# 输出推理内容
print("\n--- reasoning_content from response ---")
if hasattr(response, "reasoning_content") and response.reasoning_content:
    print(response.reasoning_content)
else:
    print("No reasoning_content found in response")


print("\n\n=== Example 3: Streaming with reasoning=True ===\n")

# 创建一个用于流式传输的新智能体
streaming_agent = Agent(
    model=OpenAIChat(id="gpt-4o"),
    reasoning=True,
    markdown=True,
)

# 打印响应（包含处理流式响应）
print("Running with reasoning=True (streaming)...")
streaming_agent.print_response(
    "What is the value of 5! (factorial)?",
    stream=True,
    show_full_reasoning=True,
)

# 从智能体的 run_response 中获取 reasoning_content 流式响应内容
print("\n--- reasoning_content from agent.run_response after streaming ---")
if (
    hasattr(streaming_agent, "run_response")
    and streaming_agent.run_response
    and hasattr(streaming_agent.run_response, "reasoning_content")
    and streaming_agent.run_response.reasoning_content
):
    print(streaming_agent.run_response.reasoning_content)
else:
    print("No reasoning_content found in agent.run_response after streaming")


print("\n\n=== Example 4: Streaming with reasoning_model ===\n")

# 创建一个配备流式推理模型的新智能体
streaming_agent_with_model = Agent(
    model=OpenAIChat(id="gpt-4o"),
    reasoning_model=OpenAIChat(id="gpt-4o"),
    markdown=True,
)

# 打印响应（包含处理流式响应）
print("Running with reasoning_model specified (streaming)...")
streaming_agent_with_model.print_response(
    "What is the value of 5! (factorial)?",
    stream=True,
    show_full_reasoning=True,
)

# 从智能体的 run_response 中获取 reasoning_content 流式传输后的内容
print("\n--- reasoning_content from agent.run_response after streaming ---")
if (
    hasattr(streaming_agent_with_model, "run_response")
    and streaming_agent_with_model.run_response
    and hasattr(streaming_agent_with_model.run_response, "reasoning_content")
    and streaming_agent_with_model.run_response.reasoning_content
):
    print(streaming_agent_with_model.run_response.reasoning_content)
else:
    print("No reasoning_content found in agent.run_response after streaming")

```

## 用法

<Steps>
  <Snippet file="create-venv-step.mdx" />

  <Step title="设置您的 API 密钥">
    ```bash
    export OPENAI_API_KEY=xxx
    ```
  </Step>

  <Step title="安装库">
    ```bash
    pip install -U openai agno
    ```
  </Step>

  <Step title="运行示例">
    <CodeGroup>
    ```bash 苹果（Mac）
    python cookbook/reasoning/agents/capture_reasoning_content_default_COT.py
    ```

    ```bash Windows
    python cookbook/reasoning/agents/capture_reasoning_content_default_COT.py
    ```
    </CodeGroup>
  </Step>
</Steps>