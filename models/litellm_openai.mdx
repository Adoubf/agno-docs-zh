---
title: LiteLLM OpenAI
description: 在Agno中使用LiteLLM与OpenAI兼容的代理服务器。
---
## 代理服务器集成

LiteLLM 可用作兼容 OpenAI 的代理服务器，允许您通过统一 API 将请求路由至不同模型。

### 启动代理服务器

首先安装包含代理支持的 LiteLLM：

```shell
pip install 'litellm[proxy]'
```

启动代理服务器：

```shell
litellm --model gpt-4o --host 127.0.0.1 --port 4000
```

### 使用代理

`LiteLLMOpenAI` 类通过兼容 OpenAI 的接口连接至 LiteLLM 代理：

```python
from agno.agent import Agent
from agno.models.litellm import LiteLLMOpenAI

agent = Agent(
    model=LiteLLMOpenAI(
        id="gpt-4o",  # Model ID to use
    ),
    markdown=True,
)

agent.print_response("Share a 2 sentence horror story")
```

### 配置选项

`LiteLLMOpenAI` 类接受以下参数：

| 参数 | 类型 | 描述 | 默认值 |
| --- | --- | --- | --- |
| `id` | str | 模型标识符 | "gpt-4o" |
| `name` | str | 模型显示名称 | "LiteLLM" |
| `provider` | str | 供应商名称 | "LiteLLM" |
| `api_key` | str | API密钥（默认回退至 LITELLM_API_KEY 环境变量） | None |
| `base_url` | str | LiteLLM 代理服务器 URL | "http://0.0.0.0:4000" |

## 示例

查阅以下 cookbook 中的示例：

### 代理示例
<Note> 查看更多示例 [请访问此处](../examples/models/litellm_openai)。 </Note>