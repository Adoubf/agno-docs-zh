---
title: Cerebras
description: 了解如何在 Agno 中使用 Cerebras 模型。
---
[Cerebras推理服务](https://inference-docs.cerebras.ai/introduction)提供由Cerebras晶圆级引擎和CS-3系统驱动的高速、低延迟AI模型推理能力。Agno直接集成Cerebras Python SDK，您可通过简洁接口使用最先进的Llama模型。

## 前提条件

使用Agno连接Cerebras需满足：

1. **安装必备软件包**：
   ```shell
   pip install cerebras-cloud-sdk
   ```

2. **设置API密钥**：
   Cerebras SDK要求将API密钥设为环境变量：
   ```shell
   export CEREBRAS_API_KEY=your_api_key_here
   ```

## 基础用法

以下示例展示如何在Agno中使用Cerebras模型：

```python
from agno.agent import Agent
from agno.models.cerebras import Cerebras

agent = Agent(
    model=Cerebras(id="llama-4-scout-17b-16e-instruct"),
    markdown=True,
)

# 在终端打印响应
agent.print_response("write a two sentence horror story")
```

## 支持模型

当前支持的模型列表（最新信息参见[文档](https://inference-docs.cerebras.ai/introduction)）：

| 模型名称                      | 模型ID                       | 参数量      | 知识截止     |
| ---------------------------- | --------------------------- | ----------- | ----------- |
| Llama 4 Scout                | llama-4-scout-17b-16e-instruct | 1090亿     | 2024年8月   |
| Llama 3.1 8B                 | llama3.1-8b                 | 80亿        | 2023年3月   |
| Llama 3.3 70B                | llama-3.3-70b               | 700亿       | 2023年12月  |
| DeepSeek R1蒸馏Llama 70B*    | deepseek-r1-distill-llama-70b | 700亿       | 2023年12月  |

\* DeepSeek R1蒸馏Llama 70B目前为私有预览版。

## 配置选项

`Cerebras` 类接收以下参数：

| 参数          | 类型           | 说明                                         | 默认值                       |
| ------------- | -------------- | ------------------------------------------- | --------------------------- |
| `id`          | str            | 模型标识符(如"llama-4-scout-17b-16e-instruct") | **必填**                   |
| `name`        | str            | 模型显示名称                                | "Cerebras"                  |
| `provider`    | str            | 供应商名称                                  | "Cerebras"                  |
| `api_key`     | Optional[str]  | API密钥(默认读取`CEREBRAS_API_KEY`环境变量)  | None                        |
| `max_tokens`  | Optional[int]  | 响应最大token数                             | None                        |
| `temperature` | float          | 采样温度                                    | 0.7                         |
| `top_p`       | float          | Top-p采样值                                 | 1.0                         |
| `request_params` | Optional[Dict[str, Any]] | 附加请求参数                  | None                        |

## 资源

- [Cerebras推理文档](https://inference-docs.cerebras.ai/introduction)
- [Cerebras API参考](https://inference-docs.cerebras.ai/api-reference/chat-completions)

### SDK示例
- 更多示例请访问[此处](../examples/models/cerebras)