---
title: 语义分块
---
语义分块是一种通过分析文本片段间嵌入向量语义相似度来划分文档的方法。它利用chonkie库识别语义发生显著变化的自然断点（根据可配置的相似度阈值）。相比固定尺寸分块，该方法能更好地保持上下文和语义完整性——确保语义相关的内容保留在同一分块中，同时仅在有意义的话题转换处进行分割。

```python
from agno.agent import Agent
from agno.document.chunking.semantic import SemanticChunking
from agno.knowledge.pdf_url import PDFUrlKnowledgeBase
from agno.vectordb.pgvector import PgVector

db_url = "postgresql+psycopg://ai:ai@localhost:5532/ai"

knowledge_base = PDFUrlKnowledgeBase(
    urls=["https://agno-public.s3.amazonaws.com/recipes/ThaiRecipes.pdf"],
    vector_db=PgVector(table_name="recipes_semantic_chunking", db_url=db_url),
    chunking_strategy=SemanticChunking(),
)
knowledge_base.load(recreate=False)  # Comment out after first run

agent = Agent(
    knowledge_base=knowledge_base,
    search_knowledge=True,
)

agent.print_response("How to make Thai curry?", markdown=True)

```

## 语义分块参数

<Snippet file="chunking-semantic.mdx" />