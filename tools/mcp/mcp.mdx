---
title: 模型上下文协议（MCP）
sidebarTitle: 概述
description: 了解如何通过Agno使用MCP，使您的智能体能够通过标准化接口与外部系统进行交互。
---
[模型上下文协议（MCP）](https://modelcontextprotocol.io)通过标准化接口使智能体能够与外部系统交互。
您可以使用Agno的MCP集成将智能体连接至任何MCP服务器。

## 使用方法

<Steps>
    <Step title="找到您想使用的 MCP 服务器">
    您可以使用任何可用的MCP服务器。查看[MCP维护者提供的GitHub仓库](https://github.com/modelcontextprotocol/servers)获取示例。
    </Step>

    <Step title="初始化 MCP 集成">
    将`MCPTools`类初始化为上下文管理器。推荐使用`command`或`url`参数定义MCP服务器。通过`command`可传入目标MCP服务器的运行命令，通过`url`可传入正在运行的MCP服务器URL。

    例如，要使用"[mcp-server-git](https://github.com/modelcontextprotocol/servers/tree/main/src/git)"服务器：

    ```python
    from agno.tools.mcp import MCPTools

    async with MCPTools(command=f"uvx mcp-server-git") as mcp_tools:
        ...
    ```
    </Step>

    <Step title="向智能体提供MCPTools">
    初始化智能体时，在`tools`参数中传入`MCPTools`类。

    智能体即可使用MCP服务器：

    ```python
    from agno.agent import Agent
    from agno.models.openai import OpenAIChat
    from agno.tools.mcp import MCPTools

    async with MCPTools(command=f"uvx mcp-server-git") as mcp_tools:
        # 设置并运行智能体
        agent = Agent(model=OpenAIChat(id="gpt-4o"), tools=[mcp_tools])
        await agent.aprint_response("What is the license for this project?", stream=True)
    ```
    </Step>

</Steps>


### 基础示例：文件系统智能体

这是一个使用[文件系统MCP服务器](https://github.com/modelcontextprotocol/servers/tree/main/src/filesystem)来探索分析文件的智能体：

```python filesystem_agent.py
import asyncio
from pathlib import Path
from textwrap import dedent

from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.tools.mcp import MCPTools
from mcp import StdioServerParameters


async def run_agent(message: str) -> None:
    """Run the filesystem agent with the given message."""

    file_path = str(Path(__file__).parent.parent.parent.parent)

    # MCP服务器访问文件系统（通过`npx`）
    async with MCPTools(f"npx -y @modelcontextprotocol/server-filesystem {file_path}") as mcp_tools:
        agent = Agent(
            model=OpenAIChat(id="gpt-4o"),
            tools=[mcp_tools],
            instructions=dedent("""\
                You are a filesystem assistant. Help users explore files and directories.

                - Navigate the filesystem to answer questions
                - Use the list_allowed_directories tool to find directories that you can access
                - Provide clear context about files you examine
                - Use headings to organize your responses
                - Be concise and focus on relevant information\
            """),
            markdown=True,
            show_tool_calls=True,
        )

        # 运行智能体
        await agent.aprint_response(message, stream=True)


# 示例用法
if __name__ == "__main__":
    # 基础示例 - 探索项目许可证
    asyncio.run(run_agent("What is the license for this project?"))
```


## 在Agno Playground中使用MCP

您可以在Agno Playground中运行MCP服务器，该平台提供了与智能体交互的网页界面。以下是在Playground中运行的GitHub智能体示例：

```python github_playground.py
import asyncio
from os import getenv
from textwrap import dedent

import nest_asyncio
from agno.agent import Agent
from agno.models.openai import OpenAIChat
from agno.playground import Playground
from agno.storage.agent.sqlite import SqliteAgentStorage
from agno.tools.mcp import MCPTools

# 允许嵌套事件循环
nest_asyncio.apply()

agent_storage_file: str = "tmp/agents.db"


async def run_server() -> None:
    """Run the GitHub agent server."""
    github_token = getenv("GITHUB_TOKEN") or getenv("GITHUB_ACCESS_TOKEN")
    if not github_token:
        raise ValueError("GITHUB_TOKEN environment variable is required")

    # 创建客户端会话以连接至MCP服务器
    async with MCPTools("npx -y @modelcontextprotocol/server-github") as mcp_tools:
        agent = Agent(
            name="MCP GitHub Agent",
            tools=[mcp_tools],
            instructions=dedent("""\
                You are a GitHub assistant. Help users explore repositories and their activity.

                - Use headings to organize your responses
                - Be concise and focus on relevant information\
            """),
            model=OpenAIChat(id="gpt-4o"),
            storage=SqliteAgentStorage(
                table_name="basic_agent",
                db_file=agent_storage_file,
                auto_upgrade_schema=True,
            ),
            add_history_to_messages=True,
            num_history_responses=3,
            add_datetime_to_instructions=True,
            markdown=True,
        )

        playground = Playground(agents=[agent])
        app = playground.get_app()

        # 在保持 MCPTools 上下文管理器运行的同时启动应用
        playground.serve(app)


if __name__ == "__main__":
    asyncio.run(run_server())
```


## 最佳实践

1. **错误处理**：始终为MCP服务器连接和操作添加适当的错误处理。

2. **资源清理**：使用`MCPTools`或`MultiMCPTools`作为异步上下文管理器确保资源清理：
```python
async with MCPTools(command) as mcp_tools:
    # 您的智能体代码位于此处
```

3. **明确指令**：向智能体提供清晰具体的指令：

```python
instructions = """
You are a filesystem assistant. Help users explore files and directories.
- Navigate the filesystem to answer questions
- Use the list_allowed_directories tool to find accessible directories
- Provide clear context about files you examine
- Be concise and focus on relevant information
"""
```

## 更多信息

- 查看使用MCP的智能体示例[请点击](https://docs.agno.com/examples/concepts/tools/mcp/airbnb)
- 获取MCP服务器集合[请访问](https://github.com/modelcontextprotocol/servers)
- 阅读[MCP文档](https://modelcontextprotocol.io/introduction)了解协议详情
- 查看Agno[Cookbook](https://github.com/agno-agi/agno/tree/main/cookbook/tools/mcp)获取更多MCP智能体示例