---
title: Assistant Tasks
sidebarTitle: Tasks
---

Tasks allow us to chain LLM responses and build complex worfklows.

In general, Assistants follow the `Input -> Output` pattern and Tasks allows us to achieve `Input -> Output 1 -> ... -> Final Output` by chaining the LLM outputs together.

## Usage

In this example, we use 3 `Tasks` to reliably generate short stories for a given `Theme` by:

1. Generate a `setting` and `genre` for a `Theme` using a Pydantic model.
2. Write a 2 sentence story about the the `setting` and `genre`.
3. Give the story a `Name`.

```python story_generator.py
from phi.llm.openai import OpenAIChat
from phi.task.llm import LLMTask
from phi.assistant import Assistant
from pydantic import BaseModel, Field

class StoryTheme(BaseModel):
    setting: str = Field(..., description="This is the context of the story. If not available, provide a random setting.",)
    genre: str = Field(..., description="This is the genre of the story. If not provided, select horror.")

get_story_theme = LLMTask(
    system_prompt="Generate a theme for a story.",
    output_model=StoryTheme,
    show_output=False,
)

write_story = LLMTask(
    llm=OpenAIChat(model="gpt-4"),
    system_prompt="Write a 2 sentence story for a given theme. It should be less than 30 words.",
)

give_story_a_name = LLMTask(
    system_prompt="Give this story a 2 word name. Format output as `Name: {name}`. Don't surround with quotes.",
)

story_assistant = Assistant(tasks=[get_story_theme, write_story, give_story_a_name])
story_assistant.cli_app(user="Theme")
```

## Example

<Steps>
  <Step title="Create a virtual environment">
    Open the `Terminal` and create an `ai` directory with a python virtual environment.

    <CodeGroup>

    ```bash Mac
    mkdir ai && cd ai

    python3 -m venv aienv
    source aienv/bin/activate
    ```

    ```bash Windows
    mkdir ai; cd ai

    python3 -m venv aienv
    aienv/scripts/activate
    ```

    </CodeGroup>

  </Step>
  <Step title="Install libraries">
    Install libraries using pip

    <CodeGroup>

    ```bash Mac
    pip install -U phidata openai
    ```

    ```bash Windows
    pip install -U phidata openai
    ```

    </CodeGroup>

  </Step>
  <Step title="Create an assistant with tasks">
    Create a file `story_generator.py` with the following contents

```python story_generator.py
from phi.llm.openai import OpenAIChat
from phi.task.llm import LLMTask
from phi.assistant import Assistant
from pydantic import BaseModel, Field

class StoryTheme(BaseModel):
    setting: str = Field(..., description="This is the context of the story. If not available, provide a random setting.",)
    genre: str = Field(..., description="This is the genre of the story. If not provided, select horror.")

get_story_theme = LLMTask(
    system_prompt="Generate a theme for a story.",
    output_model=StoryTheme,
    show_output=False,
)

write_story = LLMTask(
    llm=OpenAIChat(model="gpt-4"),
    system_prompt="Write a 2 sentence story for a given theme. It should be less than 30 words.",
)

give_story_a_name = LLMTask(
    system_prompt="Give this story a 2 word name. Format output as `Name: {name}`. Don't surround with quotes.",
)

story_assistant = Assistant(tasks=[get_story_theme, write_story, give_story_a_name])
story_assistant.cli_app(user="Theme")
```

  </Step>
  <Step title="Run the assistant">
    Run the `story_generator.py` file

```bash
python story_generator.py
```

  </Step>
  <Step title="Generate short stories">
    Test short stories for the following themes:

    ```
    Drag race in 2090 New York
    ```

    ```
    Love in 1800s Punjab
    ```

    ```
    Christmas in London year 15000AD
    ```

  </Step>
</Steps>

<Snippet file="message-us-discord.mdx" />
