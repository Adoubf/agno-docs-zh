---
title: Autonomous Conversations
sidebarTitle: Autonomous
---

With Autonomous Conversations, we let the LLM decide **if** it needs to access the knowledge base and what search parameters it needs to query the knowledge base.

Behind the scenes, we provide the `Conversation` with a set of `Functions` the LLM can call to achieve tasks. Set `function_calls=True` to make the conversation autonomous by enabling default functions for searching the **Knowledge Base** and **Memory**.

## Usage

```python auto_conversation.py
from phi.llm.openai import OpenAIChat
from phi.conversation import Conversation
from phi.knowledge.pdf import PDFUrlKnowledgeBase
from phi.vectordb.pgvector import PgVector

auto_conversation = Conversation(
    # -*- Provide the conversation with a knowledge base
    knowledge_base=PDFKnowledgeBase(
        path="data/pdfs",
        vector_db=PgVector(
            collection="pdf_documents",
            db_url=db_url,
        ),
    ),
    # -*- Let the LLM call functions to achieve tasks
    function_calls=True,
    # -*- Print the signature of called functions
    show_function_calls=True,
)
```

## Params

<ResponseField name="knowledge_base" type="KnowledgeBase">
  The knowledge base to use for this Conversation. For example: The
  `PDFKnowledgeBase` converts PDFs into vector embeddings and stores them in a
  vector db. [Read more](/blocks/kb/introduction)
</ResponseField>
<ResponseField name="function_calls" type="bool" default="False">
  Makes the conversation `Autonomous` by letting the LLM call functions to
  achieve tasks.
</ResponseField>
<ResponseField name="default_functions" type="bool" default="True">
  Add default functions to the LLM
</ResponseField>
<ResponseField name="show_function_calls" type="bool" default="False">
  Print the signature of called functions.
</ResponseField>
<ResponseField
  name="tools"
  type="List[Union[Tool, ToolRegistry, Callable, Dict]]"
>
  A list of tools provided to the LLM. Use this param to add your own functions.
  [Read more](/blocks/conversation/tools)
</ResponseField>

## Example

<Steps>
  <Step title="Create a virtual environment">
    Open the `Terminal` and create an `ai` directory with a python virtual environment.

    <CodeGroup>

    ```bash Mac
    mkdir ai && cd ai

    python3 -m venv aienv
    source aienv/bin/activate
    ```

    ```bash Windows
    mkdir ai; cd ai

    python3 -m venv aienv
    aienv/scripts/activate
    ```

    </CodeGroup>

  </Step>
  <Step title="Install libraries">
    Install libraries using pip

    <CodeGroup>

    ```bash Mac
    pip install -U phidata openai pgvector pypdf psycopg sqlalchemy
    ```

    ```bash Windows
    pip install -U phidata openai pgvector pypdf psycopg sqlalchemy
    ```

    </CodeGroup>

  </Step>
  <Step title="Start PgVector">
    Create a file `resources.py` with the following contents

```python resources.py
from phi.docker.app.postgres import PgVectorDb
from phi.docker.resources import DockerResources

# -*- PgVector running on port 5432:5432
vector_db = PgVectorDb(
    pg_user="llm",
    pg_password="llm",
    pg_database="llm",
    debug_mode=True,
)

# -*- DockerResources
dev_docker_resources = DockerResources(
    apps=[vector_db],
)
```

    Start `resources.py` using:

```bash
phi start resources.py
```

  </Step>
  <Step title="Create a Autonomous conversation">
    Create a file `auto_conversation.py` with the following contents

```python auto_conversation.py
from phi.conversation import Conversation
from phi.knowledge.pdf import PDFUrlKnowledgeBase
from phi.vectordb.pgvector import PgVector

from resources import vector_db

knowledge_base = PDFUrlKnowledgeBase(
    urls=["https://www.family-action.org.uk/content/uploads/2019/07/meals-more-recipes.pdf"],
    vector_db=PgVector(
        collection="recipes",
        db_url=vector_db.get_db_connection_local(),
    ),
)
knowledge_base.load(recreate=False)

conversation = Conversation(
    knowledge_base=knowledge_base,
    function_calls=True,
    show_function_calls=True,
)

conversation.print_response('How do I make chicken tikka salad?')
conversation.print_response('What was my last question?')
```

  </Step>
  <Step title="Run the conversation">
    Run the `auto_conversation.py` file
```bash
python auto_conversation.py
```
  </Step>
</Steps>

As `show_function_calls=True`, notice how the function calls are displayed in the response.
