---
title: Prompts
---

Under the hood an Agent will convert its `description` and `instructions` into the **system** prompt and send the input message as the **user** prompt. Understanding how these prompts are created will help you build better Agents.

<Note>
This is merely a formatting benefit, we do not alter or abstract any information.
</Note>

## System prompt

The system prompt is created using `description`, `instructions` and a number of other settings. The `description` is added to the start of the system prompt and `instructions` are added as a numbered list inside  `<instructions></instructions>` tags. For example:

```python instructions.py
from phi.agent import Agent

agent = Agent(
    description="You are a famous short story writer asked to write for a magazine",
    instructions=["You are a pilot on a plane flying from Hawaii to Japan."],
    markdown=True,
    debug_mode=True,
)
agent.print_response("Tell me a 2 sentence horror story.", stream=True)
```

Will translate to:

```js
DEBUG    ============== system ==============
DEBUG    You are a famous short story writer asked to write for a magazine
         You must follow these instructions carefully:
         <instructions>
         1. You are a pilot on a plane flying from Hawaii to Japan.
         2. Use markdown to format your answers.
         </instructions>
DEBUG    ============== user ==============
DEBUG    Tell me a 2 sentence horror story.
DEBUG    Time to first token: 0.4431s
DEBUG    Time per output token: 0.0147s
DEBUG    Throughput: 68.1266 tokens/s
```

## Set the system prompt directly

You can manually set the system prompt using the `system_prompt` parameter.

```python
from phi.agent import Agent

agent = Agent(system_prompt="Share a 2 sentence story about")
agent.print_response("Love in the year 12000.")
```

## User prompt

In most cases, the user prompt is simply the input `message` sent to the Agent.

If `knowledge` is provided and `enable_rag=True`, the user prompt is updated to include:

```python
user_prompt += f"""Use the following information from the knowledge base if it helps:"
<knowledge>
{context}
</knowledge>
"""
```

## Default System Message

By default, an Agent will create a default system message. You can disable this by setting `use_default_system_message=False`.

## Customize the default system prompt

The system prompt can be customized using:

TODO: @yash to update

<ResponseField name="description" type="str" default="None">
  A description of the Agent that is added to the start of the system message.
</ResponseField>
<ResponseField name="task" type="str" default="None">
  Describe the task the agent should achieve.
</ResponseField>
<ResponseField name="instructions" type="List[str]" default="None">
  List of instructions added to the system prompt in `<instructions>` tags. Default instructions are also created depending on values for `markdown`, `output_model` etc.
</ResponseField>
<ResponseField name="extra_instructions" type="List[str]" default="None">
  List of extra_instructions added to the default system prompt. Use these when you want to add some extra instructions at the end of the default instructions.
</ResponseField>
<ResponseField name="add_to_system_prompt" type="str" default="None">
  Add a string to the end of the default system prompt.
</ResponseField>
<ResponseField name="add_knowledge_base_instructions" type="bool" default="True">
  If True, add instructions for using the knowledge base to the system prompt if knowledge base is provided
</ResponseField>
<ResponseField name="prevent_hallucinations" type="bool" default="False">
  If True, add instructions to return "I dont know" when the agent does not know the answer.
</ResponseField>
<ResponseField name="prevent_prompt_injection" type="bool" default="False">
  If True, add instructions to prevent prompt injection attacks.
</ResponseField>
<ResponseField name="limit_tool_access" type="bool" default="False">
  If True, add instructions for limiting tool access to the default system prompt if tools are provided
</ResponseField>
<ResponseField name="add_datetime_to_instructions" type="bool" default="False">
  If True, add the current datetime to the prompt to give the agent a sense of time. This allows for relative times like "tomorrow" to be used in the prompt
</ResponseField>
<ResponseField name="markdown" type="bool" default="False">
  Add an instruction to format the output using markdown.
</ResponseField>
<ResponseField name="output_model" type="Optional[Union[str, List, Type[BaseModel]]]" default="None">
  Provide an output model for the responses. Accepts a pydantic model, list of strings where each string is a key the LLM should return a value for or just a string.
</ResponseField>
<ResponseField name="parse_output" type="bool" default="True">
  If True, the output is converted into the output_model (pydantic model or json dict). Otherwise returned as is.
</ResponseField>

## Default user message

By default, an Agent will create a default user message, which is either the input message or a message with the `context` if `enable_rag=True`. You can disable this by setting `use_default_user_message=False`.

## Customize the default user message

The user message can be customized using:

TODO: @yash to update

<ResponseField name="add_references_to_prompt" type="bool" default="False">
  Enable RAG by adding references from the knowledge base to the prompt.
</ResponseField>
<ResponseField name="add_chat_history_to_prompt" type="bool" default="False">
  Adds the formatted chat history to the user prompt.
</ResponseField>
<ResponseField name="num_history_messages" type="int" default="6">
  Number of previous messages to add to the prompt or messages.
</ResponseField>