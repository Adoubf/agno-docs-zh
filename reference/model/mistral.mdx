---
title: Mistral
---

## Example

<CodeGroup>

```python agent.py
from phi.agent import Agent
from phi.llm.Mistral import Mistral

agent = Agent(
    llm=Mistral(model="mistral-large-latest"),
    description="You help people with their health and fitness goals.",
)
agent.print_response("Share a quick healthy breakfast recipe.", markdown=True)
```

</CodeGroup>

## Mistral Params

| Parameter | Type | Default | Description |
| -- | ---- | --- | ----------- |
| `name` | `str` | `"Mistral"` | The name of the LLM. |
| `model` | `str` | `"mistral-large-latest"` | The Mistral model to use. |
| `temperature` | `float` | - | Controls randomness in output generation. |
| `max_tokens` | `int` | `1024` | Maximum number of tokens to generate. |
| `top_p` | `float` | - | Controls diversity of output generation. |
| `random_seed` | `int` | - | Seed for random number generation. |
| `safe_mode` | `bool` | - | Enables content filtering. |
| `safe_prompt` | `bool` | - | Applies content filtering to prompts. |
| `response_format` | `Union[Dict[str, Any], ChatCompletionResponseFormat]` | - | Specifies the desired response format. |
| `api_key` | `str` | - | Your Mistral API key. |
| `endpoint` | `str` | - | Custom API endpoint URL. |
| `max_retries` | `int` | - | Maximum number of API call retries. |
| `timeout` | `int` | - | Timeout for API calls in seconds. |
| `mistral_client` | `MistralClient` | - | Custom Mistral client instance. |

## LLM Params

`Mistral` is a subclass of the `LLM` class and has access to the same params

<Snippet file="llm-base-reference.mdx" />
