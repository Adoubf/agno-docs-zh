<ResponseField name="llm" type="LLM" default="OpenAIChat()">
  LLM to use for this Assistant
</ResponseField>
<ResponseField name="introduction" type="str">
  Add an introduction (from the LLM) to the chat history
</ResponseField>
<ResponseField name="name" type="str">
  Assistant name
</ResponseField>
<ResponseField name="assistant_data" type="Dict[str, Any]">
  Metadata associated with this assistant
</ResponseField>

<ResponseField name="run_id" type="str">
  Run UUID (autogenerated if not set)
</ResponseField>
<ResponseField name="run_name" type="str">
  Run name
</ResponseField>
<ResponseField name="run_data" type="Dict[str, Any]">
  Run name
</ResponseField>

<ResponseField name="user_id" type="str">
  ID of the user participating in this run
</ResponseField>
<ResponseField name="user_data" type="Dict[str, Any]">
  Metadata associated the user participating in this run
</ResponseField>

<ResponseField name="memory" type="AssistantMemory">
  Assistant Memory
</ResponseField>
<ResponseField name="add_chat_history_to_messages" type="bool">
  Add chat history to the messages sent to the LLM.
</ResponseField>
<ResponseField name="add_chat_history_to_prompt" type="bool">
  Add chat history to the prompt sent to the LLM.
</ResponseField>
<ResponseField name="num_history_messages" type="int" default="6">
  Number of previous messages to add to prompt or messages sent to the LLM.
</ResponseField>

<ResponseField name="storage" type="AssistantStorage">
  Assistant Storage
</ResponseField>
<ResponseField name="row" type="AssistantRow">
  AssistantRow from the database: DO NOT SET MANUALLY
</ResponseField>

<ResponseField name="knowledge_base" type="KnowledgeBase">
  Assistant Knowledge Base
</ResponseField>
<ResponseField name="add_references_to_prompt" type="bool">
  Add references from the knowledge base to the prompt sent to the LLM.
</ResponseField>

<ResponseField name="tools" type="List[Union]">
 A list of tools provided to the LLM. Tools are functions the model may generate JSON inputs for.
 If you provide a dict, it is not called by the model.
</ResponseField>
<ResponseField name="default_tools" type="bool">
 Add default tools to the LLM
</ResponseField>
<ResponseField name="show_tool_calls" type="bool">
 Show tool calls in LLM messages.
</ResponseField>
<ResponseField name="tool_call_limit" type="int">
 Maximum number of tool calls allowed.
</ResponseField>
<ResponseField name="tool_choice" type="Union">
 Controls which (if any) tool is called by the model.
 "none" means the model will not call a tool and instead generates a message.
 "auto" means the model can pick between generating a message or calling a tool.
 Specifying a particular function via \{"type: "function", "function": \{"name": "my_function"}}
 forces the model to call that tool.
 "none" is the default when no tools are present. "auto" is the default if tools are present.
</ResponseField>

<ResponseField name="system_prompt" type="str">
  Provide the system prompt as a string
</ResponseField>
<ResponseField name="system_prompt_function" type="Callable[..., Optional[str]]">
  Provide the system prompt as a function. This function is provided the "Assistant object" as an argument
  and should return the system_prompt as a string.

Signature:

```python
def system_prompt_function(assistant: Assistant) -> str:
    ...
```

</ResponseField>
<ResponseField name="use_default_system_prompt" type="bool">
  If True, the assistant uses a default system prompt
</ResponseField>
<ResponseField name="markdown" type="bool" default="True">
  If markdown=true, formats the output using markdown
</ResponseField>

<ResponseField name="user_prompt" type="Union">
  Provides the user prompt as a string. This will ignore the message provided to the chat function
</ResponseField>
<ResponseField name="user_prompt_function" type="Callable[..., str]">
 Provides the user prompt as a function. This function is provided the "Assistant object" and the "input message" as arguments
 and should return the user_prompt as a Union[List[Dict], str].
 If add_references_to_prompt is True, then references are also provided as an argument.
 If add_chat_history_to_prompt is True, then chat_history is also provided as an argument.

Signature:

```python
def custom_user_prompt_function(
    assistant: Assistant,
    message: Union[List[Dict], str],
    references: Optional[str] = None,
    chat_history: Optional[str] = None,
) -> Union[List[Dict], str]:
    ...
```

</ResponseField>
<ResponseField name="use_default_user_prompt" type="bool" default="True">
If True, the assistant uses a default user prompt
</ResponseField>

<ResponseField name="references_function" type="Callable[..., Optional[str]]">
Function to build references for the default `user_prompt`. This function, if provided, is called when `add_references_to_prompt` is True

Signature:

```python
def references(assistant: Assistant, query: str) -> Optional[str]:
    ...
```

</ResponseField>
<ResponseField name="chat_history_function" type="Callable[..., Optional[str]]">
Function to build the chat_history for the default `user_prompt`. This function, if provided, is called when `add_chat_history_to_prompt` is True

Signature:

```python
def chat_history(assistant: Assistant) -> str:
    ...
```

</ResponseField>

<ResponseField name="output_model" type="Union">
  FProvide an output model for the responses
</ResponseField>
<ResponseField name="parse_output" type="bool" default="True">
  f True, the output is converted into the output_model (pydantic model or json
  dict)
</ResponseField>
<ResponseField name="output" type="Any">
  Final LLM response i.e. the final output of this assistant
</ResponseField>

<ResponseField name="tasks" type="List">
  Tasks allow the Assistant to generate a response using a list of tasks If
  tasks is None or empty, a single default LLM task is created for this
  assistant
</ResponseField>
<ResponseField name="task_data" type="Dict[str, Any]">
  Metadata associated with the assistant tasks
</ResponseField>

<ResponseField name="debug_mode" type="bool">
  If True, show debug logs
</ResponseField>
<ResponseField name="monitoring" type="bool">
  If True, logs Assistant runs on phidata.com
</ResponseField>
